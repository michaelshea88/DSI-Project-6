{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Rating Prediction with Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we used data from IMDB to classify users' movie ratings. We used text analysis to parse users' reviews of one hundred movies in order to generate predictions of each user's rating. A number of predictive models were employed to classify user ratings, including decision trees and random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two separate APIs were used to collect IMDB movie data. First, the IMDB API was accessed via the Python IMDB client IMDB pie. This API was used to access information regarding the top hundred ranked movies in the IMDB database. Further, OMDB API was accessed to collect runtime and genre data for each movie. Data from each API was then joined into a single dataframe and pushed to a local PostgreSQL server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's TfidfVectorizer was used to parse the text data of each users' movie review. The TfidVectorizer is described in the documentation as a combination of the CountVectorizer and the TfidfTransformer, the latter of which transforms counts into weights signifying the importance of each token (word) in the corpus of documents.\n",
    "\n",
    "The resulting output was a dataframe with 200 columns, each representing one of the top 200 ngrams in the corpus. Besides the ngram columns, the movie ID was retained to enable SQL joins, as well as the review's associated rating to enable learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data had to be stripped of non-alpha-numeric characters prior to performing the analysis. Text data was also converted to lowercase. Additionally, data was standardized using sklearn's StandardScaler tool.\n",
    "\n",
    "It's also important to note that I binned my target into three categories:\n",
    "- low score: 1-3\n",
    "- medium score: 4-7\n",
    "- high score: 8-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both decision trees and random forest classifiers were used to predict movie ratings in this analysis. First, a decision tree classifier was built and run using ten-fold cross-validation. The resulting mean accuracy score was __.59.__\n",
    "\n",
    "Next, I performed a gridsearch to identify the optimal parameters and compare mean accruacy score with the original model. The resulting gridsearch identified a model with the following parameters: \n",
    "\n",
    "    DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
    "            max_features=50, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\n",
    "The optimal model performed significantly better than the original tree, producing an accuracy score of __.83__.\n",
    "\n",
    "Finally, I repeated the process with the random forest ensembling method. The gridsearch produced a score of also __.83__. Unfortunately due to the computation expense of running these models and issues with my notebook's kernel, I ended the analysis at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Takeaway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridsearchCV drastically improved the performance of my decision tree models, however it should be noted that gridsearch may have caused my models to be overfit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
